{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "file_path = 'data/sampled_data_wb.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2434298 entries, 0 to 2434297\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   order_dt    object\n",
      " 1   user_id     int64 \n",
      " 2   nm_id       int64 \n",
      " 3   subject_id  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 74.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка данных\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет количества покупок по категориям для каждого пользователя\n",
    "user_category_counts = df.groupby(['user_id', 'subject_id']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование столбцов в категориальный тип данных для группированных данных\n",
    "user_category_counts['user_id'] = user_category_counts['user_id'].astype('category')\n",
    "user_category_counts['subject_id'] = user_category_counts['subject_id'].astype('category')\n",
    "\n",
    "# Получение категориальных кодов для индексов строк и столбцов разреженной матрицы\n",
    "rows = user_category_counts['user_id'].cat.codes\n",
    "cols = user_category_counts['subject_id'].cat.codes\n",
    "data = user_category_counts['counts'].values\n",
    "\n",
    "# Удостоверимся, что все массивы имеют одинаковую длину\n",
    "assert len(rows) == len(cols) == len(data), \"Mismatch in lengths of the arrays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "# Создание разреженной матрицы\n",
    "sparse_matrix = coo_matrix((data, (rows, cols)), shape=(user_category_counts['user_id'].cat.categories.size, user_category_counts['subject_id'].cat.categories.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризация пользователей с использованием KMeans\n",
    "kmeans = KMeans(n_clusters=100)\n",
    "user_clusters = kmeans.fit_predict(sparse_matrix)\n",
    "\n",
    "# user_clusters['user_id'] = user_clusters['user_id'].astype('category')\n",
    "# user_clusters['subject_id'] = user_clusters['subject_id'].astype('category')\n",
    "df['user_id'] = df['user_id'].astype('category')\n",
    "df['subject_id'] = df['subject_id'].astype('category')\n",
    "# Привязка кластера к каждому пользователю\n",
    "df['cluster'] = user_clusters[df['user_id'].cat.codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_dt</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>93887832</td>\n",
       "      <td>765682228</td>\n",
       "      <td>8916</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>55238544</td>\n",
       "      <td>690882096</td>\n",
       "      <td>696</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>82094328</td>\n",
       "      <td>676729164</td>\n",
       "      <td>576</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>76104496</td>\n",
       "      <td>519119588</td>\n",
       "      <td>3036</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>60436644</td>\n",
       "      <td>632703608</td>\n",
       "      <td>9116</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434292</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>120588208</td>\n",
       "      <td>747376060</td>\n",
       "      <td>2584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434293</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>476158656</td>\n",
       "      <td>184127004</td>\n",
       "      <td>22104</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434294</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>41842508</td>\n",
       "      <td>576226376</td>\n",
       "      <td>10024</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434295</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>273388428</td>\n",
       "      <td>666005080</td>\n",
       "      <td>13988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434296</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>101725904</td>\n",
       "      <td>673966352</td>\n",
       "      <td>3068</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2295195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_dt    user_id      nm_id subject_id  cluster\n",
       "0        2024-01-01   93887832  765682228       8916       17\n",
       "1        2024-01-01   55238544  690882096        696        3\n",
       "2        2024-01-01   82094328  676729164        576       23\n",
       "3        2024-01-01   76104496  519119588       3036       61\n",
       "4        2024-01-01   60436644  632703608       9116       89\n",
       "...             ...        ...        ...        ...      ...\n",
       "2434292  2024-03-31  120588208  747376060       2584        2\n",
       "2434293  2024-03-31  476158656  184127004      22104       20\n",
       "2434294  2024-03-31   41842508  576226376      10024       55\n",
       "2434295  2024-03-31  273388428  666005080      13988        3\n",
       "2434296  2024-03-31  101725904  673966352       3068       21\n",
       "\n",
       "[2295195 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение расстояний до кластеров\n",
    "cluster_distances = kmeans.transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение топовых товаров в каждом кластере\n",
    "def get_top_items_by_cluster(df, cluster_id, top_n=200):\n",
    "    cluster_df = df[df['cluster'] == cluster_id]\n",
    "    top_items = cluster_df['nm_id'].value_counts().head(top_n).index.tolist()\n",
    "    return top_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(user_id, df, top_n=200):\n",
    "    user_cluster = df[df['user_id'] == user_id]['cluster'].values[0]\n",
    "    \n",
    "    # Получение расстояний до кластеров для текущего пользователя\n",
    "    user_index = df['user_id'].cat.codes[df['user_id'] == user_id].values[0]\n",
    "    distances = cluster_distances[user_index]\n",
    "    \n",
    "    # Сортировка кластеров по расстоянию\n",
    "    nearest_clusters = np.argsort(distances)\n",
    "    \n",
    "    # Кластеры, которые пользователь уже покупал\n",
    "    user_clusters = df[df['user_id'] == user_id]['cluster'].unique()\n",
    "    \n",
    "    # Фильтрация товаров, которые пользователь уже покупал\n",
    "    purchased_items = set(df[df['user_id'] == user_id]['nm_id'].unique())\n",
    "    \n",
    "    # Получение топовых товаров из кластеров, которые пользователь уже покупал (70 товаров)\n",
    "    top_items_from_user_clusters = []\n",
    "    for cluster in user_clusters:\n",
    "        items = get_top_items_by_cluster(df, cluster, top_n=200)\n",
    "        top_items_from_user_clusters.extend([item for item in items if item not in purchased_items])\n",
    "    random.shuffle(top_items_from_user_clusters)\n",
    "    top_items_from_user_clusters = top_items_from_user_clusters[:150]\n",
    "\n",
    "    # Получение топовых товаров из ближайших кластеров (70 товаров)\n",
    "    top_items_from_nearest_clusters = []\n",
    "    for cluster in nearest_clusters[1:10]:  # Например, 1-3 ближайшие кластеры\n",
    "        items = get_top_items_by_cluster(df, cluster, top_n=200)\n",
    "        top_items_from_nearest_clusters.extend([item for item in items if item not in purchased_items])\n",
    "    random.shuffle(top_items_from_nearest_clusters)\n",
    "    top_items_from_nearest_clusters = top_items_from_nearest_clusters[:30]\n",
    "\n",
    "    # Получение топовых товаров из кластеров подальше (50 товаров)\n",
    "    top_items_from_far_clusters = []\n",
    "    for cluster in nearest_clusters[11:30]:  # Например, 4-6 кластеры по удаленности\n",
    "        items = get_top_items_by_cluster(df, cluster, top_n=200)\n",
    "        top_items_from_far_clusters.extend([item for item in items if item not in purchased_items])\n",
    "    random.shuffle(top_items_from_far_clusters)\n",
    "    top_items_from_far_clusters = top_items_from_far_clusters[:15]\n",
    "\n",
    "    # Получение топовых товаров из совершенно далеких кластеров (10 товаров)\n",
    "    top_items_from_distant_clusters = []\n",
    "    for cluster in nearest_clusters[31:]:  # Например, кластеры 7 и далее\n",
    "        items = get_top_items_by_cluster(df, cluster, top_n=200)\n",
    "        top_items_from_distant_clusters.extend([item for item in items if item not in purchased_items])\n",
    "    random.shuffle(top_items_from_distant_clusters)\n",
    "    top_items_from_distant_clusters = top_items_from_distant_clusters[:5]\n",
    "\n",
    "    # Объединение всех рекомендаций\n",
    "    recommendations = (\n",
    "        top_items_from_user_clusters +\n",
    "        top_items_from_nearest_clusters +\n",
    "        top_items_from_far_clusters +\n",
    "        top_items_from_distant_clusters\n",
    "    )\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\donru\\AppData\\Local\\Temp\\ipykernel_19480\\3762717338.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  test_purchases = test_df.groupby('user_id')['nm_id'].apply(list).to_dict()\n"
     ]
    }
   ],
   "source": [
    "# Сортировка данных по дате заказа для правильного временного разделения\n",
    "df['order_dt'] = pd.to_datetime(df['order_dt'])\n",
    "df.sort_values(by='order_dt', inplace=True)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые выборки на основе даты\n",
    "split_date = df['order_dt'].quantile(0.7)  # 70% данных для тренировки, 30% для тестирования\n",
    "train_df = df[df['order_dt'] <= split_date]\n",
    "test_df = df[df['order_dt'] > split_date]\n",
    "\n",
    "# Фильтрация тестовой выборки, чтобы в ней были только те пользователи, которые есть в тренировочной выборке\n",
    "train_users = train_df['user_id'].unique()\n",
    "test_df = test_df[test_df['user_id'].isin(train_users)]\n",
    "\n",
    "test_users = test_df['user_id'].unique()\n",
    "test_purchases = test_df.groupby('user_id')['nm_id'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def precision_at_k(recommended_items, relevant_items, k=None):\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    recommended_items = recommended_items[:k]\n",
    "    relevant_set = set(relevant_items)\n",
    "    recommended_set = set(recommended_items)\n",
    "    intersection = recommended_set.intersection(relevant_set)\n",
    "    return len(intersection) / min(k, len(recommended_items))\n",
    "\n",
    "def diversity_at_k(recommended_items, k=None):\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    if len(recommended_items) < 2:\n",
    "        return 0\n",
    "    recommended_items = recommended_items[:k]\n",
    "    pairs = [(recommended_items[i], recommended_items[j]) for i in range(len(recommended_items)) for j in range(i + 1, len(recommended_items))]\n",
    "    diversity_score = len(set(pairs)) / (k * (k - 1) / 2)\n",
    "    return diversity_score\n",
    "\n",
    "def ndcg_at_k(recommended_items, relevant_items, k=None):\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    recommended_items = recommended_items[:k]\n",
    "    idcg = sum([1.0 / math.log2(i + 2) for i in range(min(len(relevant_items), k))])\n",
    "    dcg = sum([1.0 / math.log2(i + 2) if recommended_items[i] in relevant_items else 0 for i in range(len(recommended_items))])\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def map_at_k(recommended_items, relevant_items, k=None):\n",
    "    if k is None:\n",
    "        k = len(recommended_items)\n",
    "    recommended_items = recommended_items[:k]\n",
    "    relevant_set = set(relevant_items)\n",
    "    relevant_intersection = 0\n",
    "    precision_sum = 0.0\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        if item in relevant_set:\n",
    "            relevant_intersection += 1\n",
    "            precision_sum += relevant_intersection / (i + 1)\n",
    "    return precision_sum / min(k, len(relevant_set)) if relevant_set else 0\n",
    "\n",
    "def calculate_all_metrics(recommended_items, relevant_items, k=None):\n",
    "    precision = precision_at_k(recommended_items, relevant_items, k)\n",
    "    diversity = diversity_at_k(recommended_items, k)\n",
    "    ndcg = ndcg_at_k(recommended_items, relevant_items, k)\n",
    "    map_score = map_at_k(recommended_items, relevant_items, k)\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'diversity': diversity,\n",
    "        'ndcg': ndcg,\n",
    "        'map': map_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate_recommendations(test_users, test_purchases, train_df, num_users=100):\n",
    "    selected_users = random.sample(list(test_users), min(num_users, len(test_users)))\n",
    "    \n",
    "    all_metrics = {\n",
    "        'precision': [],\n",
    "        'diversity': [],\n",
    "        'ndcg': [],\n",
    "        'map': []\n",
    "    }\n",
    "\n",
    "    for user_id in selected_users:\n",
    "        recommended_items = recommend_items(user_id, train_df)\n",
    "        relevant_items = test_purchases.get(user_id, [])\n",
    "        \n",
    "        metrics = calculate_all_metrics(recommended_items, relevant_items)\n",
    "        all_metrics['precision'].append(metrics['precision'])\n",
    "        all_metrics['diversity'].append(metrics['diversity'])\n",
    "        all_metrics['ndcg'].append(metrics['ndcg'])\n",
    "        all_metrics['map'].append(metrics['map'])\n",
    "\n",
    "    average_metrics = {metric: np.mean(values) for metric, values in all_metrics.items()}\n",
    "\n",
    "    return average_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics for 100 users:\n",
      "Precision: 0.0006\n",
      "Diversity: 0.9658\n",
      "NDCG: 0.0084\n",
      "MAP: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Пример использования:\n",
    "# test_users - список уникальных пользователей из тестового набора данных\n",
    "# test_purchases - словарь, где ключи - user_id, а значения - список nm_id, купленных пользователем\n",
    "# k - количество рекомендаций для расчета метрик\n",
    "# num_users - количество пользователей для расчета метрик\n",
    "average_metrics_results = evaluate_recommendations(test_users, test_purchases, train_df, num_users=100)\n",
    "\n",
    "# Вывод средних значений метрик\n",
    "print(\"Average Metrics for 100 users:\")\n",
    "print(f\"Precision: {average_metrics_results['precision']:.4f}\")\n",
    "print(f\"Diversity: {average_metrics_results['diversity']:.4f}\")\n",
    "print(f\"NDCG: {average_metrics_results['ndcg']:.4f}\")\n",
    "print(f\"MAP: {average_metrics_results['map']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Metrics for 100 users:\n",
    "Precision: 0.0006\n",
    "Diversity: 0.9645\n",
    "NDCG: 0.0166\n",
    "MAP: 0.0075"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
